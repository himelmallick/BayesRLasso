% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/BayesRLassoSlice.R
\name{BayesRLassoSlice}
\alias{BayesRLassoSlice}
\title{Bayesian Reciprocal Regularization}
\usage{
BayesRLassoSlice(
  x,
  y,
  lambda.estimate = "AP",
  update.sigma2 = TRUE,
  max.steps = 11000,
  n.burn = 1000,
  n.thin = 1,
  ridge.CV = TRUE,
  a = 0.001,
  b = 0.001,
  posterior.summary.beta = "mean",
  posterior.summary.lambda = "median",
  beta.ci.level = 0.95,
  lambda.ci.level = 0.95,
  seed = 1234,
  na.rm = TRUE
)
}
\arguments{
\item{x}{A numeric matrix with standardized predictors in columns and samples in rows.}

\item{y}{A mean-centered continuous response variable with matching rows with x.}

\item{lambda.estimate}{Estimating lambda by empirical bayes ('EB'), MCMC ('MCMC'), or apriori ('AP'). Default is 'AP'.}

\item{update.sigma2}{Whether sigma2 should be updated. Default is TRUE.}

\item{max.steps}{Number of MCMC iterations. Default is 11000.}

\item{n.burn}{Number of burn-in iterations. Default is 1000.}

\item{n.thin}{Lag at which thinning should be done. Default is 1 (no thinning).}

\item{ridge.CV}{If X is rank deficient, a ridge parameter is added to the diagonal of the 
crossproduct (XtX) to allow for proper calculation of the inverse. If TRUE, the ridge parameter
is estimated by cross-validation using glmnet. Otherwise, it falls back to adding a small number (1e-05) 
without the cross-validation. Default is TRUE.}

\item{a}{If lambda.estimate = 'MCMC', shape hyperparameter for the Gamma prior on lambda. Default is 0.001.}

\item{b}{If lambda.estimate = 'MCMC', rate hyperparameter for the Gamma prior on lambda. Default is 0.001.}

\item{posterior.summary.beta}{Posterior summary measure for beta (mean, median, or mode). Default is 'mean'.}

\item{posterior.summary.lambda}{Posterior summary measure for lambda (mean, median, or mode). Default is 'median'.}

\item{beta.ci.level}{Credible interval level for beta. Default is 0.95 (95\%).}

\item{lambda.ci.level}{Credible interval level for lambda. Default is 0.95 (95\%).}

\item{seed}{Seed value for reproducibility. Default is 1234.}

\item{na.rm}{Logical. Should missing values (including NaN) be omitted from the calculations?}
}
\value{
A list containing the following components is returned:
\item{time}{Computational time in minutes.}
\item{beta}{Posterior estimates of beta.}
\item{lowerbeta}{Lower limit of the credible interval of beta.}
\item{upperbeta}{Upper limit of the credible interval of beta.}
\item{lambda}{Posterior estimate of lambda.}
\item{lambdaci}{Posterior credible interval of lambda.}
\item{beta.post}{Post-burn-in posterior samples of beta.}
\item{sigma2.post}{Post-burn-in posterior samples of sigma2.}
\item{lambda.post}{Post-burn-in posterior samples of lambda.}
}
\description{
Elliptical slice sampler for Bayesian Reciprocal LASSO using inverse Laplace prior
}
\examples{
\dontrun{

#########################
# Load Prostate dataset #
#########################

library(ElemStatLearn)
prost<-prostate

###########################################
# Scale data and prepare train/test split #
###########################################

prost.std <- data.frame(cbind(scale(prost[,1:8]),prost$lpsa))
names(prost.std)[9] <- 'lpsa'
data.train <- prost.std[prost$train,]
data.test <- prost.std[!prost$train,]

##################################
# Extract standardized variables #
##################################

y.train   = data.train$lpsa - mean(data.train$lpsa)
y.test <- data.test$lpsa - mean(data.test$lpsa)
x.train = scale(as.matrix(data.train[,1:8], ncol=8))
x.test = scale(as.matrix(data.test[,1:8], ncol=8))

###################################
# Reciprocal Bayesian LASSO (slice) #
###################################

fit_BayesRLasso_slice<- BayesRLasso(x.train, y.train, method = 'slice')
y.pred.BayesRLasso_slice<-x.test\%*\%fit_BayesRLasso_slice$beta
mean((y.pred.BayesRLasso_slice - y.test)^2) # Performance on test data

######################################
# Visualization of Posterior Samples #
######################################

##############
# Trace Plot #
##############

library(coda)
plot(mcmc(fit_BayesRLasso_slice$beta.post),density=FALSE,smooth=TRUE)

#############
# Histogram #
#############

library(psych)
multi.hist(fit_BayesRLasso_slice$beta.post,density=TRUE,main="")

}

}
\keyword{Bayesian}
\keyword{Ellipitical}
\keyword{LASSO}
\keyword{MCMC,}
\keyword{Reciprocal}
\keyword{regularization,}
\keyword{sampler,}
\keyword{slice}
